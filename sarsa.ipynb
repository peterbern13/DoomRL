{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from vizdoom import *\n",
    "from doom_src import utilities\n",
    "from collections import defaultdict\n",
    "from collections import deque\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eGreedyActionSelection(q_curr, eps):\n",
    "    '''\n",
    "    Preforms epsilon greedy action selectoin based on the Q-values.\n",
    "    \n",
    "    Args:\n",
    "        q_curr: A numpy array that contains the Q-values for each action for a state.\n",
    "        eps: The probability to select a random action. Float between 0 and 1.\n",
    "        \n",
    "    Returns:\n",
    "        index of action\n",
    "    '''\n",
    "    r = np.random.random()\n",
    "    if r < eps:\n",
    "        #eps of the time return a random index of the vector q_curr\n",
    "        return np.random.randint(0,len(q_curr))\n",
    "    else:\n",
    "        #1-eps of the time return an index of the max element of q (ties broken randomly)\n",
    "        max_index = [0]\n",
    "        for i in range(0,len(q_curr)):\n",
    "            if q_curr[i] > q_curr[max_index[0]]:\n",
    "                max_index = [i]\n",
    "            elif q_curr[i] == q_curr[max_index[0]]:\n",
    "                max_index.append(i)\n",
    "        return random.choice(max_index)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarsa(game, actions, num_episodes, gamma=1.0, alpha=0.1, \n",
    "                start_eps=0.2, final_eps=0.1, annealing_steps=1000,\n",
    "                max_episode_steps=100):\n",
    "    '''\n",
    "    Sarsa algorithm.\n",
    "    \n",
    "    Args:\n",
    "        - num_episodes: The number of episodes to train the agent for\n",
    "        - gamma: The discount factor\n",
    "        - alpha: The stepsize\n",
    "        - start_eps: The initial epsilon value for e-greedy action selection\n",
    "        - final_eps: The final epsilon value for the e-greedy action selection\n",
    "        - annealing_steps: The number of steps to anneal epsilon over\n",
    "        - max_episode_steps: The maximum number of steps an episode can take\n",
    "        \n",
    "    Returns: (Q_func, episode_rewards, episode_lengths)\n",
    "        - Q: Dictonary mapping state -> action values\n",
    "        - episode_rewards: Numpy array containing the reward of each episode during training\n",
    "        - episode_lengths: Numpy array containing the length of each episode during training\n",
    "    '''\n",
    "    Q = defaultdict(lambda: np.zeros(len(actions)))\n",
    "    episode_rewards = np.zeros(num_episodes)\n",
    "    episode_lengths = np.zeros(num_episodes)\n",
    "    \n",
    "    exploration = utilities.LinearSchedule(annealing_steps, final_eps, start_eps)\n",
    "    \n",
    "    for i in range(num_episodes):\n",
    "        if (i%10==0):\n",
    "            print('episode', i)\n",
    "        #initialize queue for stacked_frames\n",
    "        stacked_frames  =  deque([np.zeros((config['frame_size'],\n",
    "                config['frame_size']),\n",
    "                dtype=np.int) for i in range(config['stack_size'])], maxlen=4\n",
    "        ) \n",
    "        #fill the queue (initialize S)\n",
    "        frame = game.get_state().screen_buffer\n",
    "        state = utilities.stack_frames(\n",
    "              stacked_frames, frame, True, config['stack_size'], config['frame_size']\n",
    "        )\n",
    "        #Choose A greedily\n",
    "        action = eGreedyActionSelection(Q[hash(state.tostring())], exploration.value(i))\n",
    "        \n",
    "        for t in range(max_episode_steps):\n",
    "            #Take action A, observe R, done, \n",
    "            reward = game.make_action(actions[action])\n",
    "            # if episode is done, then the next state will be all black, not just the 4th frame\n",
    "            # This is so the done state is unique.\n",
    "            done = game.is_episode_finished()\n",
    "            if not done:\n",
    "                next_frame = game.get_state().screen_buffer\n",
    "            else:\n",
    "                next_frame = np.zeros(frame.shape, dtype=np.int)\n",
    "            #observe S'\n",
    "            next_state = utilities.stack_frames(stacked_frames, next_frame,\n",
    "                        done, config['frame_size'], config['frame_size']\n",
    "            )\n",
    "            next_action = eGreedyActionSelection(Q[hash(next_state.tostring())],exploration.value(i) )\n",
    "            episode_rewards[i] += reward\n",
    "            episode_lengths[i] += 1\n",
    "\n",
    "            Q[hash(state.tostring())][action] += alpha*(reward + gamma * Q[hash(next_state.tostring())][next_action] - Q[hash(state.tostring())][action])\n",
    "            if done:\n",
    "                game.new_episode()\n",
    "                break\n",
    "            state = next_state\n",
    "            action = next_action \n",
    "    \n",
    "    return Q, episode_rewards, episode_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0\n",
      "episode 10\n",
      "episode 20\n"
     ]
    }
   ],
   "source": [
    "config = utilities.get_config(\"configs/config.json\")\n",
    "# utilities.test_environment(config)\n",
    "\n",
    "\n",
    "\n",
    "config\n",
    "game, actions = utilities.create_environment(config) \n",
    "num_episodes = 50\n",
    "\n",
    "# Q, episode_rewards, episode_lengths = sarsa(game, actions, num_episodes, .9, \n",
    "#                 config['learning_rate'], config['annealing_start'],\n",
    "#                 config['annealing_stop'], config['annealing_steps'], 200                                         \n",
    "# \n",
    "\n",
    "Q, episode_rewards, episode_lengths = sarsa(game, \n",
    "    actions, num_episodes, .9, 0.2, 1, 0.01, 100, 300                                       \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(episode_rewards)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
